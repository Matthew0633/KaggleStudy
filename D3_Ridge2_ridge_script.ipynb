{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "Ridge2_ridge-script.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaO8IgcE1xOv"
      },
      "source": [
        "## Impressions and Reviews \r\n",
        "- 코드는 간단하지만 대용량 데이터를 다루면서 import gc / gc.collect() garbage collector 작동으로 메모리 관리를 하는 점이 눈에 띄었다.  \r\n",
        "- df.memory_usage(deep=True), astype('category')를 통해 메모리 사용현황을 파악하는 동시에 메모리사용을 줄이는 부분, float32, int32 사용에 의한 메모리 사용 감소도 가능하다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXBImdDS2aUa"
      },
      "source": [
        "\"\"\"\r\n",
        "Ridge Regression on TfIDF of text features and One-Hot-Encoded Categoricals\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import scipy\r\n",
        "\r\n",
        "from sklearn.linear_model import Ridge, LogisticRegression\r\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "\r\n",
        "import gc\r\n",
        "\r\n",
        "NUM_BRANDS = 2500\r\n",
        "NAME_MIN_DF = 10\r\n",
        "MAX_FEAT_DESCP = 50000\r\n",
        "\r\n",
        "print(\"Reading in Data\")\r\n",
        "\r\n",
        "df_train = pd.read_csv('../input/train.tsv', sep='\\t')\r\n",
        "df_test = pd.read_csv('../input/test.tsv', sep='\\t')\r\n",
        "\r\n",
        "df = pd.concat([df_train, df_test], 0)\r\n",
        "nrow_train = df_train.shape[0]\r\n",
        "y_train = np.log1p(df_train[\"price\"])\r\n",
        "\r\n",
        "# 가비지 컬렉터 작동 - 해제 메모리 회수\r\n",
        "del df_train\r\n",
        "gc.collect() \r\n",
        "\r\n",
        "# dataframe 메모리 사용현황 : int나 float 변환, category 변환 으로 사용량 감소 가능\r\n",
        "print(df.memory_usage(deep = True)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": false,
        "trusted": false,
        "id": "ug3eUg9i1vU8"
      },
      "source": [
        "df[\"category_name\"] = df[\"category_name\"].fillna(\"Other\").astype(\"category\")\n",
        "df[\"brand_name\"] = df[\"brand_name\"].fillna(\"unknown\")\n",
        "\n",
        "# 가장 많은 2500위 브랜드까지만 사용\n",
        "pop_brands = df[\"brand_name\"].value_counts().index[:NUM_BRANDS] \n",
        "df.loc[~df[\"brand_name\"].isin(pop_brands), \"brand_name\"] = \"Other\"\n",
        "\n",
        "df[\"item_description\"] = df[\"item_description\"].fillna(\"None\")\n",
        "df[\"item_condition_id\"] = df[\"item_condition_id\"].astype(\"category\")\n",
        "df[\"brand_name\"] = df[\"brand_name\"].astype(\"category\")\n",
        "\n",
        "print(df.memory_usage(deep = True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZD_Ckj-2i9X"
      },
      "source": [
        "print(\"Encodings\")\r\n",
        "count = CountVectorizer(min_df=NAME_MIN_DF)\r\n",
        "X_name = count.fit_transform(df[\"name\"])\r\n",
        "\r\n",
        "print(\"Category Encoders\")\r\n",
        "unique_categories = pd.Series(\"/\".join(df[\"category_name\"].unique().astype(\"str\")).split(\"/\")).unique()\r\n",
        "count_category = CountVectorizer()\r\n",
        "X_category = count_category.fit_transform(df[\"category_name\"])\r\n",
        "\r\n",
        "print(\"Descp encoders\")\r\n",
        "count_descp = TfidfVectorizer(max_features = MAX_FEAT_DESCP, # 50000\r\n",
        "                              ngram_range = (1,3),\r\n",
        "                              stop_words = \"english\")\r\n",
        "X_descp = count_descp.fit_transform(df[\"item_description\"])\r\n",
        "\r\n",
        "print(\"Brand encoders\")\r\n",
        "vect_brand = LabelBinarizer(sparse_output=True)\r\n",
        "X_brand = vect_brand.fit_transform(df[\"brand_name\"])\r\n",
        "\r\n",
        "print(\"Dummy Encoders\")\r\n",
        "X_dummies = scipy.sparse.csr_matrix(pd.get_dummies(df[[\r\n",
        "    \"item_condition_id\", \"shipping\"]], sparse = True).values) # sparse matrix class -> .toarray() 지원\r\n",
        "\r\n",
        "X = scipy.sparse.hstack((X_dummies, \r\n",
        "                         X_descp,\r\n",
        "                         X_brand,\r\n",
        "                         X_category,\r\n",
        "                         X_name)).tocsr()\r\n",
        "\r\n",
        "print([X_dummies.shape, X_category.shape, \r\n",
        "       X_name.shape, X_descp.shape, X_brand.shape])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDqW5M1u2kzP"
      },
      "source": [
        "X_train = X[:nrow_train]\r\n",
        "model = Ridge(solver = \"lsqr\", fit_intercept=False)\r\n",
        "\r\n",
        "print(\"Fitting Model\")\r\n",
        "model.fit(X_train, y_train)\r\n",
        "\r\n",
        "X_test = X[nrow_train:]\r\n",
        "preds = model.predict(X_test)\r\n",
        "\r\n",
        "df_test[\"price\"] = np.expm1(preds)\r\n",
        "df_test[[\"test_id\", \"price\"]].to_csv(\"submission_ridge.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}