{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "D7_CNN4_eda-and-lstm-cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv0XtLmwiWqd"
      },
      "source": [
        "## Impressions and Reviews  \r\n",
        "- text cls : bidirectional LSTM, GRU + Conv1D (+ Attention)의 다양한 조합\r\n",
        "- ensembling with avg preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "18784d60d3b7bdc2cf24a296519e9a93cb0c61fb",
        "id": "ifVlYWozAKaU"
      },
      "source": [
        "## General information\n",
        "\n",
        "In this kernel I'll work with data from Quora Insincere Questions Classification Competition.\n",
        "\n",
        "This dataset is interesting for NLP researching. We will try to find insincere questions which aren't usefull or are even harmful. I'll do a simple EDA and try an LSTM-CNN model. \n",
        "\n",
        "![](https://pbs.twimg.com/profile_images/1013607595616038912/pRq_huGc_400x400.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "KuGw8SSjAKaa",
        "outputId": "e151aaf6-3a5b-4330-d36d-cd401da37421"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import datetime\n",
        "import lightgbm as lgb\n",
        "from scipy import stats\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "import time\n",
        "pd.set_option('max_colwidth',400)\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten, Masking\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras.models import Model, load_model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras import backend as K\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ab0fa74be8858a2b3197cf2761c85cc6964f5600",
        "id": "eXCOXVT3AKac",
        "outputId": "65331950-dc34-4352-ec64-f158ca35a3ea"
      },
      "source": [
        "import os\n",
        "print(os.listdir(\"../input/embeddings/glove.840B.300d/\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['glove.840B.300d.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "_uuid": "2b77f6a1c831c98851143feb25c9903cb1154bf2",
        "id": "pNZmLHoHAKad"
      },
      "source": [
        "train = pd.read_csv(\"../input/train.csv\")\n",
        "test = pd.read_csv(\"../input/test.csv\")\n",
        "sub = pd.read_csv('../input/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "28c5b2320f5ef863df3d0b4e4d9175c59bd61ef0",
        "id": "cVODWvjiAKad"
      },
      "source": [
        "## Data overview\n",
        "\n",
        "This is a kernel competition, where we can't use external data. As a result we can use only train and test datasets as well as embeddings which were provided by organizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1558909b0a5c120c1d5ddc5be4f5a952fcb4971e",
        "id": "yYl2hwnbAKae",
        "outputId": "4ff9ffc9-8b3f-4f5a-c4df-13f636b4ace6"
      },
      "source": [
        "import os\n",
        "print('Available embeddings:', os.listdir(\"../input/embeddings/\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available embeddings: ['paragram_300_sl999', 'glove.840B.300d', 'wiki-news-300d-1M', 'GoogleNews-vectors-negative300']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0c7299c8895405ef00049595ead1ef89649ba71b",
        "id": "7jKhC22qAKae",
        "outputId": "88a41761-4148-4a7a-ce08-b46d6a4964a4"
      },
      "source": [
        "# target 분포 관찰\r\n",
        "train[\"target\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1225312\n",
              "1      80810\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "cdbe2595e31608b72cfbdc8d4bfc75840bfe3a0d",
        "id": "qpyKjylMAKae"
      },
      "source": [
        "We have a serious disbalance - only ~6% of data are positive. No wonder the metric for the competition is f1-score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "afaa845d44d72b9997ce037ab547ab4010701311",
        "id": "5rrFztNgAKaf",
        "outputId": "8f2f6664-a651-4b0a-dfd1-df64c60a349e"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you encourage people to adopt and not shop?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity affect space geometry?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000042bf85aa498cd78e</td>\n",
              "      <td>How did Otto von Guericke used the Magdeburg hemispheres?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000455dfa3e01eae3af</td>\n",
              "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  ...   target\n",
              "0  00002165364db923c7e6  ...        0\n",
              "1  000032939017120e6e44  ...        0\n",
              "2  0000412ca6e4628ce2cf  ...        0\n",
              "3  000042bf85aa498cd78e  ...        0\n",
              "4  0000455dfa3e01eae3af  ...        0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0817c86624cc43ea1df0eba310ba41f4f799f8da",
        "id": "_Z9qSn0KAKaf"
      },
      "source": [
        "In the dataset we have only texts of questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "54a553b7e92a2a0a3d491ccf92b437011b813c85",
        "id": "8amHnB1eAKaf",
        "outputId": "fe4118c2-ec14-4a39-a95d-e6b439835c33"
      },
      "source": [
        "# 문장 평균 단어개수\n",
        "print('Average word length of questions in train is {0:.0f}.'.format(np.mean(train['question_text'].apply(lambda x: len(x.split())))))\n",
        "print('Average word length of questions in test is {0:.0f}.'.format(np.mean(test['question_text'].apply(lambda x: len(x.split())))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average word length of questions in train is 13.\n",
            "Average word length of questions in test is 13.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7861669f72f36145c25911926a51bc688f51d473",
        "id": "n0BjOXqSAKag",
        "outputId": "0c36ac50-3cc3-4c7d-ace3-67847e6df133"
      },
      "source": [
        "# 최대 단어 길이\n",
        "print('Max word length of questions in train is {0:.0f}.'.format(np.max(train['question_text'].apply(lambda x: len(x.split())))))\n",
        "print('Max word length of questions in test is {0:.0f}.'.format(np.max(test['question_text'].apply(lambda x: len(x.split())))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max word length of questions in train is 134.\n",
            "Max word length of questions in test is 87.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1b1303137eb44cc0de3329921751c48209037562",
        "id": "T0VACcZGAKag",
        "outputId": "fdafc9f6-2623-4c31-9fac-4e72943e806b"
      },
      "source": [
        "# 문장 평균 글자수\n",
        "print('Average character length of questions in train is {0:.0f}.'.format(np.mean(train['question_text'].apply(lambda x: len(x)))))\n",
        "print('Average character length of questions in test is {0:.0f}.'.format(np.mean(test['question_text'].apply(lambda x: len(x)))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average character length of questions in train is 71.\n",
            "Average character length of questions in test is 70.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b82f366ef8b46b0115e9940c7966849023545733",
        "id": "1hTbXSsBAKag"
      },
      "source": [
        "As we can see on average questions in train and test datasets are similar, but there are quite long questions in train dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9d081b2f0d46faf01a943c309568c27f92462f94",
        "id": "22fD2VDhAKah"
      },
      "source": [
        "# train + test 전체 tokenizing\n",
        "max_features = 90000\n",
        "tk = Tokenizer(lower = True, filters='', num_words = max_features)\n",
        "full_text = list(train['question_text'].values) + list(test['question_text'].values)\n",
        "tk.fit_on_texts(full_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "33929a60e1872b73e40424daa1178a3d8fbf8f5a",
        "id": "LlawWhRjAKah"
      },
      "source": [
        "# text encoding 수행\n",
        "train_tokenized = tk.texts_to_sequences(train['question_text'].fillna('missing'))\n",
        "test_tokenized = tk.texts_to_sequences(test['question_text'].fillna('missing'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4330f6c01064b5fda4ca9661dc4f1cefb439cf75",
        "id": "wMa0uOT1AKah",
        "outputId": "8ad60d6a-88ca-4954-cbe8-30da807e1b52"
      },
      "source": [
        "# 문장 당 단어수 \n",
        "train['question_text'].apply(lambda x: len(x.split())).plot(kind='hist');\n",
        "plt.yscale('log');\n",
        "plt.title('Distribution of question text length in characters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,1,'Distribution of question text length in characters')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEICAYAAABMGMOEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAHnNJREFUeJzt3Xu8XFV99/HP14QDhKsY1JoLCSaNRp9a8YhapeXxUhNDSB+vSdF6iaRY0VbxkaDWwmOp+NSKYlFEwAhqMCDFRGIRVMALCgEvBGI0xkhOCCTcr5qE/J4/1jphZ3LmnD0nZ++ZefJ9v17zOjNrz6z9m3X27N+stfbsrYjAzMxsKE9qdwBmZtYdnDDMzKwUJwwzMyvFCcPMzEpxwjAzs1KcMMzMrBQnjGGQdI6kfx6huiZKeljSqPz4GknvHIm6c33flvTWkaqvhfX+q6S7Jd1Z97rLkvQhSee1O47dJelUSV9p07pLb6+SjpK0uoIY1kl65UjXa7tywmiQN77HJD0k6X5JP5Z0gqQdbRURJ0TEx0rWNeiGHBG3R8T+EfH4CMS+y44jImZGxJd3t+4W45gInARMj4in17nuZiQdLamvWBYR/xYRI5acC+t6m6QfjlBdkySFpNEjUd9uxrJbiSkifhAR00Yypk4y0l/2OpETxsBmR8QBwGHAGcDJwPkjvZJO2AlUZCJwT0RsancgZmUpads+sX+UoaNFhG+FG7AOeGVD2ZHAduC5+fEi4F/z/bHAt4D7gXuBH5AS8UX5NY8BDwMfBCYBAcwHbgeuK5SNzvVdA3wcuAF4EPgmcEhedjTQN1C8wAxgC7A1r+8Xhfreme8/CfgI8HtgE3AhcFBe1h/HW3NsdwMfHqSdDsqv35zr+0iu/5X5PW/PcSxq8vr/DWwE7gDekdc9pTHm/PhtwA8Lj58FXJXbezXwxsKy1wC3AQ8BG4APAPs1xPQw8AzgVOArhdceC9ya/5fXAM9uaOcPAL8EHgC+DuwzwPt6NvAH4PG8nvtz+d7AJ3Pb3gWcA+ybl50M/LSwDbwrx7FPfn4U4n7JAOtsfB8vBn6c38cvgKMLy64BPgb8KLfRd4CxheV/l/+f9wD/TLntq2l9DXEeTWH7LdumhecfD6zK67kNOGKoeoAnkz6fm4H78v3xDe1xeo7/MWAK8PbCetYCf98Qxxzg56TP529z25ye/+d/yO3znyW21UXA54HlwCO5nXfZftu9T9zpvbc7gE67MUDCyOW3A+8q/KP7E8bHSR/+vfLtKEAD1cUTO+ULSTuxfRk4YWwAnpuf8w3yzqDxA9e4Dhp2HIX6+hPGO4A1wOHA/sBlwEUNsX0xx/U84I8UdpoN9V5ISmYH5Nf+GpjfLM6G184g7TT73+PXKJkw8vPXkz7Uo4Hnk5Lb9Lx8I3BUvv9kntipDNR2O9oL+FPSh/ZV+f/4wdxWPYV2voGUaA4h7VBOaPL+dsRbKDsTWJpfewCwDPh4XvYk0peHU4GppB3b8xv+L6MHac/i+xhH2tm/Jtf7qvz40ELb/ja/333z4zPysumknd3LgB5SgtvK0NvXgPUNEOdO/4MW2/QNpM/FCwGRduyHDVUP8BTgdcCY3O6XAJc3xH878BzS9rQXMAt4Zl7PXwGP8sR2dCQpKb0qt+844FlNttuhttVFua6X5rr2ocn22yk3D0mVdwdpY2y0FfgT0sa7NdI47VAn6Do1Ih6JiMeaLL8oIlZGxCOkb3lvHKHu6nHApyJibUQ8DJwCzG0YGjstIh6LiF+Qvp0+r7GSHMtc4JSIeCgi1gH/AbylZBxvBL5UeI+ntvAejgHWRcSXImJbRPyMlFTfkJdvBaZLOjAi7ouIm0vW+ybgioi4KiK2knaW+wJ/UXjOWRFxR0TcS9rh/3mZiiUJWAC8LyLujYiHgH8jtSERsZ30zf69pKTyf/P7Go43A8sjYnlEbI+Iq4AVpATS70sR8eu8/S0pvI/XA8si4ocRsQX4KClZDaVZfWWUbdN3ktrlxkjWRMTvh6onIu6JiG9ExKO53U8nJYGiRRFxa96etkbEFRHx27yea0m9pqPyc+cDF+TtZHtEbIiIXzWJeahtFeCbEfGjXNcfGP72WwsnjPLGkbqVjf6d9E30O5LWSlpYoq71LSz/Pelbz9hSUQ7uGbm+Yt2jgacVyopHNT1K6ok0GptjaqxrXAtxNL7Hsg4DXpQPSLhf0v2kRNg/uf460s7x95KulfSSFmLaEUfeia9n5/dUpm0GcijpG+5NhZj/O5f3r28d8H1Sj+LskvUO5DDgDQ3t8zLSl5p+zd7HTv+XiHiU1DsZynDbpZXXTiD1ZFqqR9IYSV+Q9HtJD5J6cgc3fAHb6fMoaaakn0i6N7ffa3ji8zdUHEVDbau7rJvhb7+1cMIoQdILSTuOXY58yd+wT4qIw0lj4O+X9Ir+xU2qHOpb24TC/Ymkbx13k4ZMxhTiGkVhp1Oi3jtIG3Gx7m2k4aFW3J1jaqxrQ8nXb2TX91i00/tk1w/YtRFxcOG2f0S8CyB/A50DPBW4nPSNF1psm9wrmNDCeypqXNfdpPHx5xRiPigiduwcJc0CXgJ8l/QlpFldQ1lP6qEW22e/iDijxGs3AuMLMe1LGtIZbiwjaT1pmKhVJwHTgBdFxIHAX+ZyFZ6z431J2pvUC/gk8LSIOJg0x9D//MHiaGyfQbfVgV4zyPbbEZwwBiHpQEnHABeTxm5vGeA5x0iakncwD5AmvrbnxXeR5gta9WZJ0yWNAf4PcGmkw25/DewjaZakvUgTzXsXXncXMGmQIz0WA++TNFnS/qRhka9HxLZWgsuxLAFOl3SApMOA9wNlD7lcAryt8B7/pWH5z4HX5m+HU0jDAP2+BfyppLdI2ivfXijp2ZJ6JB0n6aA8rPQgO/8vniLpoEFimiXpFbltTyLN4fy45HsqugsYL6kHdvRWvgicKempAJLGSXp1vj8WOI807PJWYLak/iGkzfk9lN2OvpJf/2pJoyTtkw8pHj/kK+HS/Nq/yLGfys471qG2ryqdB3xA0gvy0UxT8nY3lANIyfp+SYew67bWqIf0mdoMbJM0E/jrwvLzgbfn7eRJ+f/4rLys8fPedFsdaMVDbL8dwQljYMskPUT6hvBh4FOkiauBTAWuJk0WXg98LiK+n5d9HPhI7o5+oIX1X0SaELuTNBH2XoCIeAD4B9KHZwPpm3jxtwWX5L/3SBpo7POCXPd1wO9IR3S8p4W4it6T17+W1PP6Wq5/SBHxbeDTwPdIw3nfa3jKmaQjcu4Cvgx8tfDah0gf4LmkXsGdwCd4InG+BViXhx9OIA0BkMeZFwNr8//jGQ0xrSaN/3+W1COYTTq8ekuZ99Tge6SjnO6UdHcuOzm/15/k2K4mffMFOJc0lr08Iu4hJcjzJD0lDwudDvwox/3iwVYcEetJR/F8iLTTW086Im3Iz3pE3Er6v15M6m08TDqa7o/5KUNtX5WJiEtI7fA10hFElzPwnGKjT5Pmou4GfkIaChxsPQ+RPm9LSAcf/C1pXql/+Q2kfcGZpC+I1/JEz/QzwOsl3SfprBLb6kAG3H47Rf/RPGZtJSmAqRGxpt2xWJJ7ofeT/i+/a3c81n7uYZjZDpJm56HA/Ujj+LeQDls1c8Iws53MIQ2f3EEabp0bHoawzENSZmZWinsYZmZWSlef/G7s2LExadKkdodhZtZVbrrpprsj4tChn7mzrk4YkyZNYsWKFe0Ow8ysq0hq5ewKO3hIyszMSnHCMDOzUpwwzMysFCcMMzMrpWMmvfMJzT4GHAisiJqvQ21mZoOrtIch6QJJmyStbCifIWm1pDV64voRc0inVt7KzifUMzOzDlD1kNQi0uU4d8jXcDgbmEm6JOQ8SdNJZ+78cUS8n3RNYzMz6yCVJoyIuI5dr1J3JLAm0mVCt5BOpTyH1Ku4Lz/n8WZ1SlogaYWkFZs3b64ibDMzG0A75jDGsfNlCfuAF5HOJf9ZSUeRrtcwoIg4l3T9AHp7e4d9IqxJC68Y7kt327ozZrVt3WZmw9Uxk975QjHzh3wi6RTMwOwpU6ZUG5SZme3QjsNqN7Dz9ZzH0+J1kyNiWUQsOOigZlfbNDOzkdaOhHEjMDVfV7qHdPnCpUO8Zif5Ii/nPvDAA5UEaGZmu6r6sNrFpOtcT5PUJ2l+RGwDTgSuBFYBS/K1hM3MrINVOocREfOalC8Hlu9GvcuAZb29vccPtw4zM2uNTw1iZmaldGXC8ByGmVn9ujJh+CgpM7P6dWXCcA/DzKx+XZkw3MMwM6tfVyYMMzOrX1cmDA9JmZnVrysThoekzMzq15UJw8zM6ueEYWZmpXTM6c33JO26Foevw2Fmu6Mrexie9DYzq19XJgxPepuZ1a8rE4aZmdXPCcPMzEpxwjAzs1K6MmF40tvMrH5dmTA86W1mVr+uTBhmZlY/JwwzMyvFCcPMzEpxwjAzs1KcMMzMrJSOSRiSjpb0A0nnSDq63fGYmdnOKk0Yki6QtEnSyobyGZJWS1ojaWEuDuBhYB+gr8q4zMysdVX3MBYBM4oFkkYBZwMzgenAPEnTgR9ExEzgZOC0iuMyM7MWVZowIuI64N6G4iOBNRGxNiK2ABcDcyJie15+H7B3szolLZC0QtKKzZs3VxK3mZntqh1zGOOA9YXHfcA4Sa+V9AXgIuA/m704Is6NiN6I6D300EMrDtXMzPp1zBX3IuIy4LIyz5U0G5g9ZcqUaoMyM7Md2tHD2ABMKDwen8tK87mkzMzq146EcSMwVdJkST3AXGBpKxX4bLVmZvWr+rDaxcD1wDRJfZLmR8Q24ETgSmAVsCQibm2lXvcwzMzqV+kcRkTMa1K+HFg+3Ho9h2FmVr+O+aV3K9zDMDOrX1cmDM9hmJnVrysThnsYZmb165jfYbTCcxjDM2nhFW1b97ozZrVt3WY2MtzDMDOzUroyYZiZWf2cMMzMrJSuTBg+SsrMrH5dmTA8h2FmVr+uTBhmZlY/JwwzMyulKxOG5zDMzOrXlQnDcxhmZvXryoRhZmb1c8IwM7NSnDDMzKwUJwwzMyulKxOGj5IyM6tfVyYMHyVlZla/rkwYZmZWPycMMzMrxQnDzMxKccIwM7NSOiphSNpP0gpJx7Q7FjMz21mlCUPSBZI2SVrZUD5D0mpJayQtLCw6GVhSZUxmZjY8VfcwFgEzigWSRgFnAzOB6cA8SdMlvQq4DdhUcUxmZjYMo6usPCKukzSpofhIYE1ErAWQdDEwB9gf2I+URB6TtDwitlcZn9Vn0sIr2rLedWfMast6zf5/VGnCaGIcsL7wuA94UUScCCDpbcDdzZKFpAXAAoCJEydWG6mZme3QjoQxqIhYNMTycyVtBGb39PS8oJ6ozMysHUdJbQAmFB6Pz2Wl+dQgZmb1a0fCuBGYKmmypB5gLrC0lQp88kEzs/pVfVjtYuB6YJqkPknzI2IbcCJwJbAKWBIRt7ZSr3sYZmb1q/ooqXlNypcDy4dbr6TZwOwpU6YMtwozM2tRR/3Suyz3MMzM6teVCcNzGGZm9evKhOEehplZ/UolDEn/o+pAWuEehplZ/cr2MD4n6QZJ/yCp7V/r3cMwM6tfqYQREUcBx5F+cHeTpK/lkwWamdkeovQcRkT8BvgI6RTkfwWcJelXkl5bVXBmZtY5ys5h/JmkM0k/tHs5MDsinp3vn1lhfM3i8RyGmVnNyvYwPgvcDDwvIt4dETcDRMQdpF5HrTyHYWZWv7K/9J4FPBYRjwNIehKwT0Q8GhEXVRadmZl1jLI9jKuBfQuPx+QyMzPbQ5RNGPtExMP9D/L9MdWENDTPYZiZ1a9swnhE0hH9DyS9AHismpCG5jkMM7P6lZ3D+CfgEkl3AAKeDrypsqjMzKzjlEoYEXGjpGcB03LR6ojYWl1YZmbWaVq5HsYLgUn5NUdIIiIurCQqMzPrOKUShqSLgGcCPwcez8UBOGGYme0hyvYweoHpERFVBlOWr7hnZla/skdJrSRNdHcEHyVlZla/sj2MscBtkm4A/thfGBHHVhKVmZl1nLIJ49QqgzAzs85X9rDaayUdBkyNiKsljQFGVRuamZl1krKnNz8euBT4Qi4aB1xeVVBmZtZ5yk56vxt4KfAg7LiY0lNHMhBJz5Z0jqRLJb1rJOs2M7PdVzZh/DEitvQ/kDSa9DuMQUm6QNImSSsbymdIWi1pjaSFABGxKiJOAN5ISk5mZtZByiaMayV9CNg3X8v7EmBZidctAmYUCySNAs4GZgLTgXmSpudlxwJXAMtLxmVmZjUpmzAWApuBW4C/J+3Qh7zSXkRcB9zbUHwksCYi1uZey8XAnPz8pRExEziuZFxmZlaTskdJbQe+mG+7axywvvC4D3iRpKOB1wJ7M0gPQ9ICYAHAxIkTRyAcMzMro+y5pH7HAHMWEXH4SAUSEdcA15R43rmSNgKze3p6XjBS6zczs8G1ci6pfvsAbwAOGeY6NwATCo/H57LSImIZsKy3t/f4YcZgZmYtKjWHERH3FG4bIuLTwKxhrvNGYKqkyZJ6gLnA0lYq8CVazczqV/aHe0cUbr2STqBE70TSYuB6YJqkPknzI2IbcCJwJbAKWBIRt7YStE8+aGZWv7JDUv9RuL8NWEf6vcSgImJek/Ll7Mahsz69uZlZ/coeJfU/qw6kFZ7DMDOrX9mjpN4/2PKI+NTIhFOOexhmZvUr+8O9XuBdpN9QjANOAI4ADsi3WnkOw8ysfmXnMMYDR0TEQwCSTgWuiIg3VxWYmZl1lrI9jKcBWwqPt+SytvBhtWZm9SubMC4EbpB0au5d/BT4cmVRDcFDUmZm9St7lNTpkr4NHJWL3h4RP6suLDMz6zRlexgAY4AHI+IzQJ+kyRXFNCQPSZmZ1a/sL73/BTgZOCUX7QV8paqghuIhKTOz+pXtYfwv4FjgEYCIuIM2HE5rZmbtUzZhbImIIJ/iXNJ+1YVkZmadqGzCWCLpC8DBko4HrmZkLqY0LJ7DMDOrX9nTm38SuBT4BjAN+GhEfLbKwIaIx3MYZmY1K3OK8lHA1fkEhFdVH5KZmXWiIXsYEfE4sF2Sv86bme3Byp5L6mHgFklXkY+UAoiI91YSlZmZdZyyCeOyfDMzsz3UoAlD0sSIuD0i2nbeqIH4ehhmZvUbag7j8v47kr5RcSyl+SgpM7P6DZUwVLh/eJWBmJlZZxsqYUST+2ZmtocZatL7eZIeJPU09s33yY8jIg6sNDozM+sYgyaMiBhVVyBmZtbZyh5WWwtJfwPMAg4Ezo+I77Q5JDMzy1q5gNKwSLpA0iZJKxvKZ0haLWmNpIUAEXF5RBwPnAC8qerYzMysvMoTBrAImFEsyOenOhuYCUwH5kmaXnjKR/JyMzPrEJUnjIi4Dri3ofhIYE1ErI2ILcDFwBwlnwC+HRE3Vx2bmZmVV0cPYyDjgPWFx3257D3AK4HXSzphoBdKWiBphaQVmzdvrj5SMzMDOmzSOyLOAs4a4jnnStoIzO7p6XlBPZGZmVm7ehgbgAmFx+NzWSk+NYiZWf3alTBuBKZKmiypB5gLLC37Yl+i1cysfnUcVrsYuB6YJqlP0vyI2AacCFwJrAKWRMStZet0D8PMrH6Vz2FExLwm5cuB5cOp06c3t7ImLbyiLetdd8astqzXrErtGpLaLe5hmJnVrysThucwzMzq15UJwz0MM7P6dWXCMDOz+nVlwvCQlJlZ/boyYXhIysysfl2ZMMzMrH5dmTA8JGVmVr+uTBgekjIzq19XJgwzM6ufE4aZmZXSlQnDcxhmZvXryoThOQwzs/p1ZcIwM7P6OWGYmVkpThhmZlaKE4aZmZXSlQnDR0mZmdWvKxOGj5IyM6tfVyYMMzOrnxOGmZmV4oRhZmalOGGYmVkpThhmZlZKxyQMSYdLOl/Spe2OxczMdlVpwpB0gaRNklY2lM+QtFrSGkkLASJibUTMrzIeMzMbvqp7GIuAGcUCSaOAs4GZwHRgnqTpFcdhZma7qdKEERHXAfc2FB8JrMk9ii3AxcCcsnVKWiBphaQVmzdvHsFozcxsMO2YwxgHrC887gPGSXqKpHOA50s6pdmLI+Jc4DTg5p6enmojNTOzHTpm0jsi7omIEyLimRHx8SGe61ODmJnVrB0JYwMwofB4fC4rzScfNDOrXzsSxo3AVEmTJfUAc4GlrVTgHoaZWf2qPqx2MXA9ME1Sn6T5EbENOBG4ElgFLImIW1us1z0MM7Oaja6y8oiY16R8ObB8N+pdBizr7e09frh1mJlZazpm0rsV7mGYmdWvKxOG5zDMzOrXlQnDzMzq15UJw0NSZmb168qE4SEpM7P6dWXCMDOz+nVlwvCQlJlZ/boyYXhIysysfl2ZMMzMrH5OGGZmVkpXJgzPYZiZ1a8rE4bnMMzM6teVCcPMzOrnhGFmZqU4YZiZWSlOGGZmVkpXJgwfJWVmVr+uTBg+SsrMrH5dmTDMzKx+ThhmZlaKE4aZmZXihGFmZqU4YZiZWSmj2x1AP0n7AZ8DtgDXRMRX2xySmZkVVNrDkHSBpE2SVjaUz5C0WtIaSQtz8WuBSyPieODYKuMyM7PWVT0ktQiYUSyQNAo4G5gJTAfmSZoOjAfW56c9XnFcZmbWokqHpCLiOkmTGoqPBNZExFoASRcDc4A+UtL4OYMkMkkLgAUAEydOHPmgzcxKmrTwirate90Zs2pfZzsmvcfxRE8CUqIYB1wGvE7S54FlzV4cEecCpwE39/T0VBmnmZkVdMykd0Q8Ary95HOXAct6e3uPrzYqMzPr144exgZgQuHx+FxWmk8+aGZWv3YkjBuBqZImS+oB5gJLW6nAJx80M6tf1YfVLgauB6ZJ6pM0PyK2AScCVwKrgCURcWuL9bqHYWZWs6qPkprXpHw5sHw36vUchplZzbry1CDuYZiZ1a8rE4bnMMzM6teVCcPMzOqniGh3DC2TNBuYDbwJ+E2LLx8L3D3iQVXPcdenG2MGx123boy7P+bDIuLQVl/clQljd0haERG97Y6jVY67Pt0YMzjuunVj3Lsbs4ekzMysFCcMMzMrZU9MGOe2O4Bhctz16caYwXHXrRvj3q2Y97g5DDMzG549sYdhZmbD4IRhZmal7DEJo8l1xDuOpAmSvi/pNkm3SvrHXH6IpKsk/Sb/fXK7Yx2IpFGSfibpW/nxZEk/ze3+9XyG4o4i6WBJl0r6laRVkl7S6e0t6X15+1gpabGkfTq1rSVdIGmTpJWFsgHbV8lZ+T38UtIRHRTzv+dt5JeS/kvSwYVlp+SYV0t6dTtiznHsEndh2UmSQtLY/Ljltt4jEsYg1xHvRNuAkyJiOvBi4N051oXAdyNiKvDd/LgT/SPpLMT9PgGcGRFTgPuA+W2JanCfAf47Ip4FPI8Uf8e2t6RxwHuB3oh4LjCKdJmATm3rRcCMhrJm7TsTmJpvC4DP1xRjo0XsGvNVwHMj4s+AXwOnAOTP51zgOfk1n8v7nHZYxK5xI2kC8NfA7YXiltt6j0gYFK4jHhFbgP7riHeciNgYETfn+w+Rdl7jSPF+OT/ty8DftCfC5iSNB2YB5+XHAl4OXJqf0nFxSzoI+EvgfICI2BIR99P57T0a2FfSaGAMsJEObeuIuA64t6G4WfvOAS6M5CfAwZL+pJ5InzBQzBHxnXx5BoCfkC7+BinmiyPijxHxO2ANaZ9TuyZtDXAm8EGgeJRTy229pySMZtcR72iSJgHPB34KPC0iNuZFdwJPa1NYg/k0aaPcnh8/Bbi/8CHrxHafDGwGvpSH0s6TtB8d3N4RsQH4JOnb4kbgAeAmOr+ti5q1b7d8Vt8BfDvf7+iYJc0BNkTELxoWtRz3npIwuo6k/YFvAP8UEQ8Wl0U6FrqjjoeWdAywKSJuancsLRoNHAF8PiKeDzxCw/BTp7V3Hu+fQ0p2zwD2Y4BhiG7Rae07FEkfJg0df7XdsQxF0hjgQ8BHR6K+PSVh7PZ1xOskaS9SsvhqRFyWi+/q7y7mv5vaFV8TLwWOlbSONOT3ctLcwMF52AQ6s937gL6I+Gl+fCkpgXRye78S+F1EbI6IrcBlpPbv9LYuata+Hf1ZlfQ24BjguHjiR2ydHPMzSV8sfpE/m+OBmyU9nWHEvackjN2+jnhd8rj/+cCqiPhUYdFS4K35/luBb9Yd22Ai4pSIGB8Rk0jt+72IOA74PvD6/LROjPtOYL2kabnoFcBtdHZ73w68WNKYvL30x9zRbd2gWfsuBf4uH8HzYuCBwtBVW0maQRpyPTYiHi0sWgrMlbS3pMmkSeQb2hFjo4i4JSKeGhGT8mezDzgib/ett3VE7BE34DWkIxt+C3y43fEMEufLSN3zXwI/z7fXkOYDvks6nfvVwCHtjnWQ93A08K18/3DSh2cNcAmwd7vjGyDePwdW5Da/HHhyp7c3cBrwK2AlcBGwd6e2NbCYNNeyNe+w5jdrX0CkIxp/C9xCOhKsU2JeQxrz7/9cnlN4/odzzKuBmZ3U1g3L1wFjh9vWPjWImZmVsqcMSZmZ2W5ywjAzs1KcMMzMrBQnDDMzK8UJw8zMSnHCMDOzUpwwzMyslP8HQUl7tsEt0P8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "05c7e2c63afb343b64835432721a42f81dd53626",
        "id": "Bm5eBF4JAKai"
      },
      "source": [
        "We can see that most of the questions are 40 words long or shorter. Let's try having sequence length equal to 70 for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0a3f7fc48edb7d8d4aec66042dfb45e5af225c44",
        "id": "hX4rbxVbAKai"
      },
      "source": [
        "# 70 - padding 수행\n",
        "max_len = 70\n",
        "X_train = pad_sequences(train_tokenized, maxlen = max_len)\n",
        "X_test = pad_sequences(test_tokenized, maxlen = max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "744ee4a1fbc66cb47aae6a18f829dea284b860c9",
        "id": "wGttCPxMAKai"
      },
      "source": [
        "# glove pretrained embedding 사용\n",
        "embedding_path = \"../input/embeddings/glove.840B.300d/glove.840B.300d.txt\"\n",
        "#embedding_path = \"../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "5cd86c2400db5ea1511b107250c8aa8c98ea909b",
        "id": "65erqeb9AKai"
      },
      "source": [
        "embed_size = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "2948d63cafb76b446c5e167a6dce7915ca43da6d",
        "id": "4PQ8QPlNAKaj",
        "outputId": "68fdfa0f-8e57-450a-bca5-f951062af336"
      },
      "source": [
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embedding_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_path, encoding='utf-8', errors='ignore'))\n",
        "all_embs = np.stack(embedding_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "\n",
        "word_index = tk.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words + 1, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9011f3f1e1affbe0795e2f7a98d4f0e98a8c4925",
        "id": "Mw49ukMDAKaj",
        "outputId": "468209d4-c9b3-4d54-b3b9-71931242fcf8"
      },
      "source": [
        "# target 원핫인코딩\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "y_ohe = ohe.fit_transform(train['target'].values.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "58c29867982a695f802700c77ebb213a52e18659",
        "id": "4OQi2eexAKaj"
      },
      "source": [
        "For now I'll use an architecture from my previous [kernel](https://www.kaggle.com/artgor/movie-review-sentiment-analysis-eda-and-models) in another competition.\n",
        "\n",
        "The architecture in the following:\n",
        "- input with embedding;\n",
        "- then we have separate \"branches\" - GRU and LSTM;\n",
        "- each \"branch\" is processed by two Conv1D layers separately;\n",
        "- each Conv1D layer has average and max pooling layers;\n",
        "- all pooling layers are concatenated;\n",
        "- two dense layers in the end;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "55bc04ce8d311a8176886a211217d4e4459d4700",
        "id": "0_X_e9v0AKak"
      },
      "source": [
        "# embedding -> BiGRU, BiLSTM -> Conv1D x 2 -> Concat -> BN -> FC\n",
        "def build_model(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32, epochs=20):\n",
        "    # callbacks 지정\n",
        "    file_path = \"best_model.hdf5\"\n",
        "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                                  save_best_only = True, mode = \"min\")\n",
        "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
        "\n",
        "\n",
        "    \n",
        "    inp = Input(shape = (max_len,)) # (?, 70)\n",
        "    x = Embedding(max_features + 1, embed_size, weights = [embedding_matrix], trainable = False)(inp) # (?, 70, 300)\n",
        "    x1 = SpatialDropout1D(spatial_dr)(x)  # (?, 70, 300)\n",
        "\n",
        "    x_gru = Bidirectional(CuDNNGRU(units, return_sequences = True))(x1)  # (?, 70, 64), (?, 70, 64) -> (?, 70, 128)\n",
        "    x_lstm = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x1)  # (?, 70, 64), (?, 70, 64) -> (?, 70, 128)\n",
        "    \n",
        "    x_conv1 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_gru) #  (?, 70-4+1, 16)\n",
        "    avg_pool1_gru = GlobalAveragePooling1D()(x_conv1) #  (?,  16)\n",
        "    max_pool1_gru = GlobalMaxPooling1D()(x_conv1) #  (?, 16)\n",
        "    \n",
        "    x_conv2 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_gru) #  (?, 70-3+1, 16)\n",
        "    avg_pool2_gru = GlobalAveragePooling1D()(x_conv2) #  (?, 16)\n",
        "    max_pool2_gru = GlobalMaxPooling1D()(x_conv2) #  (?, 16)\n",
        "    \n",
        "    \n",
        "    x_conv3 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_lstm) #  (?, 70-4+1, 16)\n",
        "    avg_pool1_lstm = GlobalAveragePooling1D()(x_conv3) #  (?,  16)\n",
        "    max_pool1_lstm = GlobalMaxPooling1D()(x_conv3) #  (?,  16)\n",
        "    \n",
        "    x_conv4 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_lstm) #  (?, 70-3+1, 16)\n",
        "    avg_pool2_lstm = GlobalAveragePooling1D()(x_conv4) #  (?,  16)\n",
        "    max_pool2_lstm = GlobalMaxPooling1D()(x_conv4) #  (?,  16)\n",
        "    \n",
        "    \n",
        "    x = concatenate([avg_pool1_gru, max_pool1_gru, avg_pool2_gru, max_pool2_gru,\n",
        "                    avg_pool1_lstm, max_pool1_lstm, avg_pool2_lstm, max_pool2_lstm]) #  (?,  16) * 8 -> (?, 16*8)\n",
        "    x = BatchNormalization()(x) #  (?, 16*8)\n",
        "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x)) #  (?, 16)\n",
        "    x = BatchNormalization()(x) #  (?, 16)\n",
        "    x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x)) #  (?, 8)\n",
        "    x = Dense(2, activation = \"sigmoid\")(x) #  (?, 2)\n",
        "    model = Model(inputs = inp, outputs = x)\n",
        "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
        "    model.summary()\n",
        "    history = model.fit(X_train, y_ohe, \n",
        "                        batch_size = 512,\n",
        "                        epochs = epochs,\n",
        "                        validation_split=0.1, \n",
        "                        verbose = 1, \n",
        "                        callbacks = [check_point, early_stop])\n",
        "    model = load_model(file_path)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "90ac92a570fe3c180252dfcf1f22c5f98a08e615",
        "id": "A02udIhpAKal",
        "outputId": "40e84ea0-bae6-4aa7-d81d-fb88a04ee751"
      },
      "source": [
        "%%time\n",
        "model = build_model(lr = 1e-4, lr_d = 0, units = 64, spatial_dr = 0.5, kernel_size1=4, kernel_size2=3, dense_units=16, dr=0.1, conv_size=16, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 70)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 70, 300)      27000300    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_1 (SpatialDro (None, 70, 300)      0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 70, 128)      140544      spatial_dropout1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 70, 128)      187392      spatial_dropout1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 67, 16)       8208        bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 68, 16)       6160        bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 67, 16)       8208        bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 68, 16)       6160        bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_1 (Glo (None, 16)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 16)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_2 (Glo (None, 16)           0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 16)           0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_3 (Glo (None, 16)           0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_3 (GlobalM (None, 16)           0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_4 (Glo (None, 16)           0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_4 (GlobalM (None, 16)           0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 128)          0           global_average_pooling1d_1[0][0] \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "                                                                 global_average_pooling1d_2[0][0] \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "                                                                 global_average_pooling1d_3[0][0] \n",
            "                                                                 global_max_pooling1d_3[0][0]     \n",
            "                                                                 global_average_pooling1d_4[0][0] \n",
            "                                                                 global_max_pooling1d_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 128)          512         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 16)           2064        batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 16)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 16)           64          dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 8)            136         batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 8)            0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            18          dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 27,359,766\n",
            "Trainable params: 359,178\n",
            "Non-trainable params: 27,000,588\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1175509 samples, validate on 130613 samples\n",
            "Epoch 1/5\n",
            "1175509/1175509 [==============================] - 296s 252us/step - loss: 0.3297 - acc: 0.8718 - val_loss: 0.1438 - val_acc: 0.9399\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.14381, saving model to best_model.hdf5\n",
            "Epoch 2/5\n",
            "1175509/1175509 [==============================] - 291s 248us/step - loss: 0.1828 - acc: 0.9381 - val_loss: 0.1371 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.14381 to 0.13708, saving model to best_model.hdf5\n",
            "Epoch 3/5\n",
            " 682496/1175509 [================>.............] - ETA: 1:57 - loss: 0.1657 - acc: 0.9405"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8b206256803deeb5ba630578da1175b3cc01f555",
        "id": "9lkSWbX8AKal"
      },
      "source": [
        "# pred = model.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "# predictions = np.round(np.argmax(pred, axis=1)).astype(int)\n",
        "# sub['prediction'] = predictions\n",
        "# sub.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "754211d82f222f50cbb19712aca94984b2191588",
        "id": "enJGCtakAKal"
      },
      "source": [
        "# BiGRU 1개만 사용, BiGRUx1 - Conv1D x2\n",
        "\n",
        "def build_model1(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32, epochs=20):\n",
        "    file_path = \"best_model.hdf5\"\n",
        "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                                  save_best_only = True, mode = \"min\")\n",
        "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
        "\n",
        "    inp = Input(shape = (max_len,))\n",
        "    x = Embedding(max_features + 1, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
        "    x1 = SpatialDropout1D(spatial_dr)(x)\n",
        "\n",
        "    x_gru = Bidirectional(CuDNNGRU(units, return_sequences = True))(x1)\n",
        "    \n",
        "    x_conv1 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
        "    avg_pool1_gru = GlobalAveragePooling1D()(x_conv1)\n",
        "    max_pool1_gru = GlobalMaxPooling1D()(x_conv1)\n",
        "    \n",
        "    x_conv2 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
        "    avg_pool2_gru = GlobalAveragePooling1D()(x_conv2)\n",
        "    max_pool2_gru = GlobalMaxPooling1D()(x_conv2)\n",
        "\n",
        "    \n",
        "    \n",
        "    x = concatenate([avg_pool1_gru, max_pool1_gru, avg_pool2_gru, max_pool2_gru])\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n",
        "    x = Dense(2, activation = \"sigmoid\")(x)\n",
        "\n",
        "    model = Model(inputs = inp, outputs = x)\n",
        "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
        "    model.summary()\n",
        "    history = model.fit(X_train, y_ohe,\n",
        "                        batch_size = 512, \n",
        "                        epochs = epochs, \n",
        "                        validation_split=0.1, \n",
        "                        verbose = 1, \n",
        "                        callbacks = [check_point, early_stop])\n",
        "    model = load_model(file_path)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "552f593475f579d8c2822ee6c2d6b52ed1abc3e5",
        "id": "Jc_dLC0uAKam"
      },
      "source": [
        "#model1 = build_model1(lr = 1e-4, lr_d = 1e-7, units = 128, spatial_dr = 0.3, kernel_size1=4, kernel_size2=3, dense_units=32, dr=0.3, conv_size=32, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0055ab6717740b4b234ada9aacb0c78074e64b55",
        "id": "_dD3tClfAKan"
      },
      "source": [
        "#model1_1 = build_model1(lr = 1e-4, lr_d = 1e-7, units = 128, spatial_dr = 0.3, kernel_size1=4, kernel_size2=3, dense_units=32, dr=0.1, conv_size=32, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "836e8eec34c09dcca660d35f39ddd5ec4801147a",
        "id": "sVMOX_aCAKan"
      },
      "source": [
        "# BiGRU 2개 사용, BiGRUx1 - Conv1D x2\n",
        "\n",
        "def build_model2(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32, epochs=20):\n",
        "    file_path = \"best_model.hdf5\"\n",
        "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                                  save_best_only = True, mode = \"min\")\n",
        "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
        "\n",
        "    inp = Input(shape = (max_len,))\n",
        "    x = Embedding(max_features + 1, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
        "    x1 = SpatialDropout1D(spatial_dr)(x)\n",
        "\n",
        "    x_gru = Bidirectional(CuDNNGRU(units * 2, return_sequences = True))(x1)\n",
        "    x_gru = Bidirectional(CuDNNGRU(units, return_sequences = True))(x_gru)\n",
        "    \n",
        "    x_conv1 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
        "    avg_pool1_gru = GlobalAveragePooling1D()(x_conv1)\n",
        "    max_pool1_gru = GlobalMaxPooling1D()(x_conv1)\n",
        "    \n",
        "    x_conv2 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
        "    avg_pool2_gru = GlobalAveragePooling1D()(x_conv2)\n",
        "    max_pool2_gru = GlobalMaxPooling1D()(x_conv2)\n",
        "  \n",
        "    x = concatenate([avg_pool1_gru, max_pool1_gru, avg_pool2_gru, max_pool2_gru])\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n",
        "    x = Dense(2, activation = \"sigmoid\")(x)\n",
        "    model = Model(inputs = inp, outputs = x)\n",
        "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
        "    model.summary()\n",
        "    history = model.fit(X_train, y_ohe, \n",
        "                        batch_size = 512, \n",
        "                        epochs = epochs, \n",
        "                        validation_split=0.1, \n",
        "                        verbose = 1, callbacks = [check_point, early_stop])\n",
        "    model = load_model(file_path)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0284b87509f5b94a6d03db579be74dad0bc8ff73",
        "id": "_gW7tOTVAKan"
      },
      "source": [
        "#%%time\n",
        "#model2 = build_model2(lr = 1e-4, lr_d = 1e-7, units = 256, spatial_dr = 0.3, kernel_size1=4, kernel_size2=3, dense_units=32, dr=0.1, conv_size=32, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ac612d038ef7cf161c4e7c678751d29e4e2c7a82",
        "id": "N4Y6B0p6AKao"
      },
      "source": [
        "#model3 = build_model2(lr = 1e-3, lr_d = 1e-7, units = 256, spatial_dr = 0.3, kernel_size1=4, kernel_size2=3, dense_units=32, dr=0.1, conv_size=16, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3f6b13c224c17bf70eac09f9bc3846d8332fa8d4",
        "id": "U8TQ9XhPAKao",
        "outputId": "2a7ad0e7-099b-4e3e-eb09-fc4f9b467d2c"
      },
      "source": [
        "%%time\n",
        "model4 = build_model2(lr = 1e-4, lr_d = 1e-7, units = 64, spatial_dr = 0.3, kernel_size1=4, kernel_size2=3, dense_units=32, dr=0.1, conv_size=8, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 70)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 70, 300)      27000300    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_2 (SpatialDro (None, 70, 300)      0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 70, 256)      330240      spatial_dropout1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) (None, 70, 128)      123648      bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 67, 8)        4104        bidirectional_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 68, 8)        3080        bidirectional_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_5 (Glo (None, 8)            0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_5 (GlobalM (None, 8)            0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_6 (Glo (None, 8)            0           conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_6 (GlobalM (None, 8)            0           conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32)           0           global_average_pooling1d_5[0][0] \n",
            "                                                                 global_max_pooling1d_5[0][0]     \n",
            "                                                                 global_average_pooling1d_6[0][0] \n",
            "                                                                 global_max_pooling1d_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32)           128         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 32)           1056        batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32)           0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32)           128         dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 16)           528         batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 16)           0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 2)            34          dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 27,463,246\n",
            "Trainable params: 462,818\n",
            "Non-trainable params: 27,000,428\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1175509 samples, validate on 130613 samples\n",
            "Epoch 1/5\n",
            "1175509/1175509 [==============================] - 334s 284us/step - loss: 0.2000 - acc: 0.9309 - val_loss: 0.1326 - val_acc: 0.9495\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.13262, saving model to best_model.hdf5\n",
            "Epoch 2/5\n",
            "1175509/1175509 [==============================] - 331s 282us/step - loss: 0.1417 - acc: 0.9474 - val_loss: 0.1265 - val_acc: 0.9509\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.13262 to 0.12647, saving model to best_model.hdf5\n",
            "Epoch 3/5\n",
            "1175509/1175509 [==============================] - 331s 281us/step - loss: 0.1333 - acc: 0.9498 - val_loss: 0.1282 - val_acc: 0.9514\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.12647\n",
            "Epoch 4/5\n",
            "1175509/1175509 [==============================] - 331s 282us/step - loss: 0.1276 - acc: 0.9515 - val_loss: 0.1202 - val_acc: 0.9530\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.12647 to 0.12022, saving model to best_model.hdf5\n",
            "Epoch 5/5\n",
            "1175509/1175509 [==============================] - 332s 283us/step - loss: 0.1238 - acc: 0.9526 - val_loss: 0.1170 - val_acc: 0.9538\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.12022 to 0.11700, saving model to best_model.hdf5\n",
            "CPU times: user 18min 13s, sys: 6min 22s, total: 24min 35s\n",
            "Wall time: 27min 54s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "582cadcbd9fdd70e4c6da7160d743057fd9a487e",
        "id": "n3Sfxc_BAKao"
      },
      "source": [
        "#model5 = build_model2(lr = 1e-4, lr_d = 1e-7, units = 256, spatial_dr = 0.1, kernel_size1=4, kernel_size2=3, dense_units=32, dr=0.1, conv_size=16, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "04d92de6fc799aca62d3b41c588973d2480b2672",
        "id": "aPbS_dqDAKao"
      },
      "source": [
        "### Model with attention\n",
        "\n",
        "https://github.com/Diyago/ML-DL-scripts/blob/9e161a96580efa9993805ca28f610df72fe36406/DEEP%20LEARNING/LSTM%20RNN/Sentiment%20analysis%20LSTM%20wth%20Bidirectional%20%20%2B%20Custom%20Attention.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0571d9edafb014eb480950a8c67fb892a4780240",
        "id": "aXnkDTZTAKao"
      },
      "source": [
        "class Attention(Layer):\n",
        "    def __init__(self, step_dim,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        \"\"\"\n",
        "        Keras Layer that implements an Attention mechanism for temporal data.\n",
        "        Supports Masking.\n",
        "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
        "        # Input shape\n",
        "            3D tensor with shape: `(samples, steps, features)`.\n",
        "        # Output shape\n",
        "            2D tensor with shape: `(samples, features)`.\n",
        "        :param kwargs:\n",
        "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "        The dimensions are inferred based on the output shape of the RNN.\n",
        "        Example:\n",
        "            model.add(LSTM(64, return_sequences=True))\n",
        "            model.add(Attention())\n",
        "        \"\"\"\n",
        "        self.supports_masking = True\n",
        "        #self.init = initializations.get('glorot_uniform')\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        # eij = K.dot(x, self.W) TF backend doesn't support it\n",
        "\n",
        "        # features_dim = self.W.shape[0]\n",
        "        # step_dim = x._keras_shape[1]\n",
        "\n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "    #print weigthted_input.shape\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        #return input_shape[0], input_shape[-1]\n",
        "        return input_shape[0],  self.features_dim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "143768540a1c3ad0783e49362e9018b7d46a1f07",
        "id": "gdXu5r0fAKap"
      },
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "19030bd2b6277b9e5dbc6933ca0abcf68fc7b3f9",
        "id": "d-E38XBIAKap"
      },
      "source": [
        "def build_model3(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, dense_units=128, dr=0.1, use_attention=True):\n",
        "    inp = Input(shape = (max_len,))\n",
        "    x = Embedding(max_features + 1, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
        "    x1 = SpatialDropout1D(spatial_dr)(x)\n",
        "\n",
        "    x_gru = Bidirectional(CuDNNGRU(units * 2, return_sequences = True))(x1)\n",
        "    if use_attention:\n",
        "        x_att = Attention(max_len)(x_gru)\n",
        "        x = Dropout(dr)(Dense(dense_units, activation='relu') (x_att))\n",
        "    else:\n",
        "        x_att = Flatten() (x_gru)\n",
        "        x = Dropout(dr)(Dense(dense_units, activation='relu') (x_att))\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    #x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n",
        "    x = Dense(2, activation = \"sigmoid\")(x)\n",
        "    model = Model(inputs = inp, outputs = x)\n",
        "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
        "    #model.summary()\n",
        "    #history = model.fit(X_train, y_ohe, batch_size = 512, epochs = epochs, validation_split=0.1, \n",
        "    #                    verbose = 1, callbacks = [check_point, early_stop])\n",
        "    #model = load_model(file_path)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1e7072209b383437e44560d062c1614418a1607a",
        "id": "URdDN8uIAKap",
        "outputId": "e2b905ec-717c-4420-e65e-be8140e45872"
      },
      "source": [
        "%%time\n",
        "file_path = \"best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                              save_best_only = True, mode = \"min\")\n",
        "\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
        "\n",
        "model6 = build_model3(lr = 1e-3, lr_d = 1e-7, units = 64, spatial_dr = 0.3, dense_units=16, dr=0.1, use_attention=True)\n",
        "\n",
        "history = model6.fit(X_train, y_ohe, \n",
        "                     batch_size = 512, \n",
        "                     epochs = 10, \n",
        "                     validation_split=0.1, \n",
        "                    verbose = 1, callbacks = [check_point, early_stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1175509 samples, validate on 130613 samples\n",
            "Epoch 1/10\n",
            "1175509/1175509 [==============================] - 204s 174us/step - loss: 0.1703 - acc: 0.9376 - val_loss: 0.1184 - val_acc: 0.9540\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.11836, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "1175509/1175509 [==============================] - 201s 171us/step - loss: 0.1212 - acc: 0.9531 - val_loss: 0.1125 - val_acc: 0.9559\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.11836 to 0.11252, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "1175509/1175509 [==============================] - 200s 170us/step - loss: 0.1159 - acc: 0.9546 - val_loss: 0.1101 - val_acc: 0.9570\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.11252 to 0.11013, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "1175509/1175509 [==============================] - 200s 170us/step - loss: 0.1120 - acc: 0.9558 - val_loss: 0.1081 - val_acc: 0.9567\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.11013 to 0.10810, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "1175509/1175509 [==============================] - 200s 170us/step - loss: 0.1090 - acc: 0.9567 - val_loss: 0.1078 - val_acc: 0.9572\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.10810 to 0.10779, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            " 506368/1175509 [===========>..................] - ETA: 1:49 - loss: 0.1063 - acc: 0.9576"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4c0cab2368cf13a33e56a92eec20ac01254c3529",
        "id": "QfcitggUAKap"
      },
      "source": [
        "# #%%time\n",
        "# file_path = \"best_model.hdf5\"\n",
        "# check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "#                               save_best_only = True, mode = \"min\")\n",
        "# early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
        "# model6_1 = build_model3(lr = 1e-3, lr_d = 1e-7, units = 64, spatial_dr = 0.3, dense_units=16, dr=0.1, use_attention=False)\n",
        "# history = model6_1.fit(X_train, y_ohe, batch_size = 512, epochs = 5, validation_split=0.1, \n",
        "#                     verbose = 1, callbacks = [check_point, early_stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "bbc608b1a70e5bc21df515136b6225da29e797a9",
        "id": "hFaqECAtAKap"
      },
      "source": [
        "### One branch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "fecf3405fccd307de507cea500df6b559e70cc95",
        "id": "WWHL7l0vAKaq"
      },
      "source": [
        "# GRUx1 -> Conv1D x1 사용\n",
        "def build_model4(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32, epochs=20):\n",
        "    file_path = \"best_model.hdf5\"\n",
        "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                                  save_best_only = True, mode = \"min\")\n",
        "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
        "\n",
        "    inp = Input(shape = (max_len,))\n",
        "    x = Embedding(max_features + 1, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
        "    x1 = SpatialDropout1D(spatial_dr)(x)\n",
        "\n",
        "    x_gru = Bidirectional(CuDNNGRU(units, return_sequences = True))(x1)\n",
        "    \n",
        "    x_conv1 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
        "    avg_pool1_gru = GlobalAveragePooling1D()(x_conv1)\n",
        "    max_pool1_gru = GlobalMaxPooling1D()(x_conv1)\n",
        "       \n",
        "    x = concatenate([avg_pool1_gru, max_pool1_gru])\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n",
        "    x = BatchNormalization()(x)\n",
        "    #x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n",
        "    x = Dense(2, activation = \"sigmoid\")(x)\n",
        "    model = Model(inputs = inp, outputs = x)\n",
        "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
        "    model.summary()\n",
        "    history = model.fit(X_train, y_ohe, batch_size = 512, epochs = epochs, validation_split=0.1, \n",
        "                        verbose = 1, callbacks = [check_point, early_stop])\n",
        "    model = load_model(file_path)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "29fcf5b25f20763deb75612eac29d58add377fee",
        "id": "Ndam01fQAKaq",
        "outputId": "4fe0b3bf-49fe-488a-f7c2-51d2f553ff4b"
      },
      "source": [
        "%%time\n",
        "model7 = build_model4(lr = 1e-4, lr_d = 1e-7, units = 64, spatial_dr = 0.3, kernel_size1=3, dense_units=32, dr=0.1, conv_size=8, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 70)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 70, 300)      27000300    input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_4 (SpatialDro (None, 70, 300)      0           embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) (None, 70, 128)      140544      spatial_dropout1d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 68, 8)        3080        bidirectional_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_7 (Glo (None, 8)            0           conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_7 (GlobalM (None, 8)            0           conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 16)           0           global_average_pooling1d_7[0][0] \n",
            "                                                                 global_max_pooling1d_7[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16)           64          concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 32)           544         batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32)           0           dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32)           128         dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 2)            66          batch_normalization_7[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 27,144,726\n",
            "Trainable params: 144,330\n",
            "Non-trainable params: 27,000,396\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1175509 samples, validate on 130613 samples\n",
            "Epoch 1/5\n",
            "1175509/1175509 [==============================] - 146s 125us/step - loss: 0.4302 - acc: 0.8300 - val_loss: 0.1878 - val_acc: 0.9490\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.18780, saving model to best_model.hdf5\n",
            "Epoch 2/5\n",
            "1175509/1175509 [==============================] - 143s 122us/step - loss: 0.1657 - acc: 0.9448 - val_loss: 0.1320 - val_acc: 0.9498\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.18780 to 0.13201, saving model to best_model.hdf5\n",
            "Epoch 3/5\n",
            "1175509/1175509 [==============================] - 143s 121us/step - loss: 0.1398 - acc: 0.9480 - val_loss: 0.1256 - val_acc: 0.9514\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.13201 to 0.12564, saving model to best_model.hdf5\n",
            "Epoch 4/5\n",
            "1175509/1175509 [==============================] - 143s 121us/step - loss: 0.1319 - acc: 0.9495 - val_loss: 0.1223 - val_acc: 0.9524\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.12564 to 0.12232, saving model to best_model.hdf5\n",
            "Epoch 5/5\n",
            "1175509/1175509 [==============================] - 142s 121us/step - loss: 0.1284 - acc: 0.9506 - val_loss: 0.1207 - val_acc: 0.9528\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.12232 to 0.12074, saving model to best_model.hdf5\n",
            "CPU times: user 8min 59s, sys: 2min 33s, total: 11min 33s\n",
            "Wall time: 12min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1b21c1b068660aaca49e9f1d1c8259bd5c97ad56",
        "id": "iCChxVAtAKaq"
      },
      "source": [
        "#model8 = build_model4(lr = 1e-4, lr_d = 1e-7, units = 128, spatial_dr = 0.3, kernel_size1=4, dense_units=32, dr=0.1, conv_size=8, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f12bb4ca1ee7bca3caa41426590330365e057d34",
        "id": "uSreOrV_AKaq"
      },
      "source": [
        "### Masking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "dcae5f568eac0945c349eb2253df8010d03faa97",
        "id": "p1s6Xfg4AKaq"
      },
      "source": [
        "# Embedding -> masking -> LSTM -> BN -> FC 생략\n",
        "\n",
        "def build_model5(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32, epochs=20):\n",
        "    file_path = \"best_model.hdf5\"\n",
        "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                                  save_best_only = True, mode = \"min\")\n",
        "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                              patience=2, min_lr=0.001)\n",
        "\n",
        "    inp = Input(shape = (max_len,))\n",
        "    x = Embedding(max_features + 1, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
        "    x1 = SpatialDropout1D(spatial_dr)(x)\n",
        "    x_m = Masking()(x1)\n",
        "    x_gru = LSTM(units)(x_m)\n",
        "\n",
        "    x = BatchNormalization()(x_gru)\n",
        "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n",
        "    x = BatchNormalization()(x)\n",
        "    #x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n",
        "    x = Dense(2, activation = \"sigmoid\")(x)\n",
        "    model = Model(inputs = inp, outputs = x)\n",
        "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
        "    model.summary()\n",
        "    history = model.fit(X_train, y_ohe, batch_size = 512, epochs = epochs, validation_split=0.1, \n",
        "                        verbose = 1, callbacks = [check_point, early_stop, reduce_lr])\n",
        "    model = load_model(file_path)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3b98e6c57a2f16b29b8ae7265919eb309e36e770",
        "id": "b-GkcyQ3AKar"
      },
      "source": [
        "#model9 = build_model5(lr = 1e-4, lr_d = 1e-7, units = 128, spatial_dr = 0.3, kernel_size1=4, dense_units=32, dr=0.1, conv_size=8, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "771278144d9fe02f509ee4e08b7a97d3e69b8283",
        "id": "_KjmRZMIAKar",
        "outputId": "7b5c1438-a1ab-4e4a-c36f-8699aa90bf1b"
      },
      "source": [
        "# 최종 pred: ensemble -> pred avg 값\n",
        "\n",
        "pred1 = model.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "pred = pred1\n",
        "pred4 = model4.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "pred += pred4\n",
        "pred2 = model7.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "pred += pred2\n",
        "# pred3 = model9.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "# pred += pred3\n",
        "pred4 = model6.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "pred += pred4\n",
        "# pred5 = model7.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "# pred += pred5\n",
        "pred = pred / 4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56370/56370 [==============================] - 5s 90us/step\n",
            "56370/56370 [==============================] - 6s 104us/step\n",
            "56370/56370 [==============================] - 3s 56us/step\n",
            "56370/56370 [==============================] - 4s 71us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "2c04e298f5c96a9561450874a0238f408984c39e",
        "id": "T2uB5cK2AKar"
      },
      "source": [
        "#pred = model9.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "\n",
        "predictions = np.round(np.argmax(pred, axis=1)).astype(int)\n",
        "sub['prediction'] = predictions\n",
        "sub.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}