{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "Ridge4_more-effective-ridge-lgbm-script-lb-0-44823.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4Z19Bbh3_Yz"
      },
      "source": [
        "## Impressions and Reviews  \r\n",
        "- brand imputation은 \"missing\"으로 fill, 너무나 simple\r\n",
        "- lgbm, ridge 간의 57 : 43 으로 ensemble\r\n",
        "- 가장 많은 도수의 brand 약 4000개 까지 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGfQOuWt3-yp"
      },
      "source": [
        "import gc\r\n",
        "import time\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "from scipy.sparse import csr_matrix, hstack\r\n",
        "\r\n",
        "from sklearn.linear_model import Ridge\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\r\n",
        "import lightgbm as lgb\r\n",
        "\r\n",
        "NUM_BRANDS = 4004\r\n",
        "NUM_CATEGORIES = 1001\r\n",
        "NAME_MIN_DF = 10\r\n",
        "MAX_FEATURES_ITEM_DESCRIPTION = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": false,
        "trusted": false,
        "id": "MeXWKMme3I_x"
      },
      "source": [
        "def handle_missing_inplace(dataset):\n",
        "    dataset['category_name'].fillna(value='missing', inplace=True)\n",
        "    dataset['brand_name'].fillna(value='missing', inplace=True)\n",
        "    dataset['item_description'].fillna(value='missing', inplace=True)\n",
        "\n",
        "\n",
        "def cutting(dataset):\n",
        "    pop_brand = dataset['brand_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_BRANDS] # 'missing' category 데이터 제외, 도수많은 4004까지\n",
        "    dataset.loc[~dataset['brand_name'].isin(pop_brand), 'brand_name'] = 'missing'\n",
        "    pop_category = dataset['category_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_BRANDS]\n",
        "    dataset.loc[~dataset['category_name'].isin(pop_category), 'category_name'] = 'missing'\n",
        "\n",
        "\n",
        "def to_categorical(dataset):\n",
        "    dataset['category_name'] = dataset['category_name'].astype('category')\n",
        "    dataset['brand_name'] = dataset['brand_name'].astype('category')\n",
        "    dataset['item_condition_id'] = dataset['item_condition_id'].astype('category')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frWtLbB04Hba"
      },
      "source": [
        "start_time = time.time()\r\n",
        "\r\n",
        "train = pd.read_table('../input/train.tsv', engine='c')\r\n",
        "test = pd.read_table('../input/test.tsv', engine='c')\r\n",
        "print('[{}] Finished to load data'.format(time.time() - start_time))\r\n",
        "print('Train shape: ', train.shape)\r\n",
        "print('Test shape: ', test.shape)\r\n",
        "\r\n",
        "nrow_train = train.shape[0]\r\n",
        "y = np.log1p(train[\"price\"])\r\n",
        "\r\n",
        "# a:int = 1\r\n",
        "# a -> 1\r\n",
        "\r\n",
        "merge: pd.DataFrame = pd.concat([train, test])\r\n",
        "submission: pd.DataFrame = test[['test_id']]\r\n",
        "\r\n",
        "del train\r\n",
        "del test\r\n",
        "gc.collect()\r\n",
        "\r\n",
        "handle_missing_inplace(merge)\r\n",
        "print('[{}] Finished to handle missing'.format(time.time() - start_time))\r\n",
        "\r\n",
        "cutting(merge)\r\n",
        "print('[{}] Finished to cut'.format(time.time() - start_time))\r\n",
        "\r\n",
        "to_categorical(merge)\r\n",
        "print('[{}] Finished to convert categorical'.format(time.time() - start_time))\r\n",
        "\r\n",
        "cv = CountVectorizer(min_df=NAME_MIN_DF)\r\n",
        "X_name = cv.fit_transform(merge['name'])\r\n",
        "print('[{}] Finished count vectorize `name`'.format(time.time() - start_time))\r\n",
        "\r\n",
        "cv = CountVectorizer()\r\n",
        "X_category = cv.fit_transform(merge['category_name'])\r\n",
        "print('[{}] Finished count vectorize `category_name`'.format(time.time() - start_time))\r\n",
        "\r\n",
        "tv = TfidfVectorizer(max_features=MAX_FEATURES_ITEM_DESCRIPTION,\r\n",
        "                      ngram_range=(1, 3),\r\n",
        "                      stop_words='english')\r\n",
        "X_description = tv.fit_transform(merge['item_description'])\r\n",
        "print('[{}] Finished TFIDF vectorize `item_description`'.format(time.time() - start_time))\r\n",
        "\r\n",
        "lb = LabelBinarizer(sparse_output=True)\r\n",
        "X_brand = lb.fit_transform(merge['brand_name'])\r\n",
        "print('[{}] Finished label binarize `brand_name`'.format(time.time() - start_time))\r\n",
        "\r\n",
        "X_dummies = csr_matrix(pd.get_dummies(merge[['item_condition_id', 'shipping']],\r\n",
        "                                      sparse=True).values)\r\n",
        "print('[{}] Finished to get dummies on `item_condition_id` and `shipping`'.format(time.time() - start_time))\r\n",
        "\r\n",
        "sparse_merge = hstack((X_dummies, X_description, X_brand, X_category, X_name)).tocsr()\r\n",
        "print('[{}] Finished to create sparse merge'.format(time.time() - start_time))\r\n",
        "\r\n",
        "X = sparse_merge[:nrow_train]\r\n",
        "X_test = sparse_merge[nrow_train:]\r\n",
        "\r\n",
        "#train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size = 0.1, random_state = 144) \r\n",
        "d_train = lgb.Dataset(X, label=y)\r\n",
        "#d_valid = lgb.Dataset(valid_X, label=valid_y, max_bin=8192)\r\n",
        "#watchlist = [d_train, d_valid]\r\n",
        "\r\n",
        "params = {\r\n",
        "    'learning_rate': 0.75,\r\n",
        "    'application': 'regression',\r\n",
        "    'max_depth': 3,\r\n",
        "    'num_leaves': 100,\r\n",
        "    'verbosity': -1,\r\n",
        "    'metric': 'RMSE',\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "# lgbm 57% + Ridge 43% 앙상블 적용\r\n",
        "model = lgb.train(params, train_set=d_train, num_boost_round=3200, verbose_eval=100) \r\n",
        "preds = 0.57*model.predict(X_test)\r\n",
        "\r\n",
        "\r\n",
        "model = Ridge(solver=\"sag\", fit_intercept=True, random_state=205)\r\n",
        "model.fit(X, y)\r\n",
        "print('[{}] Finished to train ridge'.format(time.time() - start_time))\r\n",
        "preds += 0.43*model.predict(X=X_test)\r\n",
        "print('[{}] Finished to predict ridge'.format(time.time() - start_time))\r\n",
        "\r\n",
        "\r\n",
        "submission['price'] = np.expm1(preds)\r\n",
        "submission.to_csv(\"submission_lgbm_ridge_5.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}